{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e106e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"\"\n",
    "\n",
    "#root should contain:\n",
    "# State_median_housing values.csv    [must have 2 columns labeled 'State' and 'Median Housing Value', download here: https://factfinder.census.gov/faces/nav/jsf/pages/searchresults.xhtml?refresh=t#none]\n",
    "# ACS 2019    [folder with unzipped .gdb for each state, download here: https://www2.census.gov/geo/tiger/TIGER_DP/]\n",
    "# state shp   [folder with unzipped .shp and associated files for each state. This program uses a combination of preprocessed HPMS 2016 and 2017, download here: https://www.fhwa.dot.gov/policyinformation/hpms/shapefiles_2017.cfm]\n",
    "\n",
    "### program will output 3 csv files into the root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8290e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import time\n",
    "import pandas\n",
    "from math import log10\n",
    "import gc\n",
    "import os\n",
    "import geopy.distance\n",
    "import warnings\n",
    "import math\n",
    "import utm\n",
    "from pyproj import CRS\n",
    "warnings.filterwarnings('ignore')  #this is set to 'ignore' due to a section with frequent pandas merging that draws a warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08973407",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_value = pandas.read_csv(root+\"\\\\State_median_housing values.csv\")\n",
    "#change in hv per dBA from indirect valuation, Deluchi and Hsu (1998) and median housing value see methodology section in paper\n",
    "hv = {}\n",
    "for i in range(len(house_value)):\n",
    "    #annual change per dBA by state = median housing value * annualitzation rate * near road adjustment factor * % reduction per dBA\n",
    "    hv[house_value.iloc[i]['State']] = house_value.iloc[i]['Median Housing Value']*.0650*.95*.0085\n",
    "\n",
    "files = os.listdir(root+r\"\\ACS 2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed36380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This list is used for reference between state FIPS, ABB, name, and UTM code\n",
    "STATES_DATA = [['01', 'AL', 'Alabama', '16'],\n",
    "               ['02', 'AK', 'Alaska', '5'],\n",
    "               ['04', 'AZ', 'Arizona', '12'],\n",
    "               ['05', 'AR', 'Arkansas', '15'],\n",
    "               ['06', 'CA', 'California', '11'],\n",
    "               ['08', 'CO', 'Colorado', '13'],\n",
    "               ['09', 'CT', 'Connecticut', '18'],\n",
    "               ['10', 'DE', 'Delaware', '18'],\n",
    "               ['11', 'DC', 'District of Columbia', '18'],\n",
    "               ['12', 'FL', 'Florida', '17'],\n",
    "               ['13', 'GA', 'Georgia', '17'],\n",
    "               ['15', 'HI', 'Hawaii', '4'],\n",
    "               ['16', 'ID', 'Idaho', '11'],\n",
    "               ['17', 'IL', 'Illinois', '16'],\n",
    "               ['18', 'IN', 'Indiana', '16'],\n",
    "               ['19', 'IA', 'Iowa', '15'],\n",
    "               ['20', 'KS', 'Kansas', '14'],\n",
    "               ['21', 'KY', 'Kentucky', '16'],\n",
    "               ['22', 'LA', 'Louisiana', '15'],\n",
    "               ['23', 'ME', 'Maine', '19'],\n",
    "               ['24', 'MD', 'Maryland', '18'],\n",
    "               ['25', 'MA', 'Massachusetts', '19'],\n",
    "               ['26', 'MI', 'Michigan', '16'],\n",
    "               ['27', 'MN', 'Minnesota', '15'],\n",
    "               ['28', 'MS', 'Mississippi', '16'],\n",
    "               ['29', 'MO', 'Missouri', '15'],\n",
    "               ['30', 'MT', 'Montana', '12'],\n",
    "               ['31', 'NE', 'Nebraska', '14'],\n",
    "               ['32', 'NV', 'Nevada', '11'],\n",
    "               ['33', 'NH', 'New Hampshire', '19'],\n",
    "               ['34', 'NJ', 'New Jersey', '18'],\n",
    "               ['35', 'NM', 'New Mexico', '13'],\n",
    "               ['36', 'NY', 'New York', '18'],\n",
    "               ['37', 'NC', 'North Carolina', '17'],\n",
    "               ['38', 'ND', 'North Dakota', '14'],\n",
    "               ['39', 'OH', 'Ohio', '17'],\n",
    "               ['40', 'OK', 'Oklahoma', '14'],\n",
    "               ['41', 'OR', 'Oregon', '10'],\n",
    "               ['42', 'PA', 'Pennsylvania', '18'],\n",
    "               #['72', 'PR', 'Puerto Rico', '19'],\n",
    "               ['44', 'RI', 'Rhode Island', '19'],\n",
    "               ['45', 'SC', 'South Carolina', '17'],\n",
    "               ['46', 'SD', 'South Dakota', '14'],\n",
    "               ['47', 'TN', 'Tennessee', '16'],\n",
    "               ['48', 'TX', 'Texas', '14'],\n",
    "               ['49', 'UT', 'Utah', '12'],\n",
    "               ['50', 'VT', 'Vermont', '18'],\n",
    "               ['51', 'VA', 'Virginia', '17'],\n",
    "               ['53', 'WA', 'Washington', '10'],\n",
    "               ['54', 'WV', 'West Virginia', '17'],\n",
    "               ['55', 'WI', 'Wisconsin', '16'],\n",
    "               ['56', 'WY', 'Wyoming', '13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4639a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = pandas.DataFrame(STATES_DATA,columns=['FIPS','ST'])\n",
    "# s.to_csv(r\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88d63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle class distribution from FHWA, see Tehcnical Report p. 106 Federal Highway Administration (FHWA), Vehicle Classification and Weight Distribution System, 2017, unpublished.\n",
    "#this is used to distribute the traffic counts from passenger vehicle, single unit truck, and combination truck into 20 different vehicle classes based on weight and axle configuration\n",
    "veh_class = {'single': [0.798344485,0.172881753,0.028773762],\n",
    "            'combination': [0.012392679,0.050868298,0.737375027,0.084669144,0.023194662,0.004540104,0.0000250647895381742,0.000942812,0.008944798,0.03569885,0.01332327,0.000131528,0.000276449,0.006229683,0.021387625]}\n",
    "#NPCE adjustment calculated as ratio of composite noise level for a given vehicle class to composite noise level for passenger cars. Concept from Hokanson (1981), see Technical Report p. 24-25 for more details\n",
    "#this is used to convert the traffic count for different vehicle classes for each roadway into a single count for easier noise calculation\n",
    "speed_npce = {'single':{10:[130.2,230.2,364.3],\n",
    "                        15:[67.24776174,118.886678,188.1257003],\n",
    "                        25:[29.24585834,51.70347465,81.81532649],\n",
    "                        35:[16.89957076,29.87659033,47.27657103],\n",
    "                        45:[11.21941438,19.83469592,31.38632623],\n",
    "                       55:[8.08938308,14.30114337,22.63005962],\n",
    "                       65:[6.161093716,10.89213895,17.23566763],\n",
    "                       75:[6.161093716,10.89213895,17.23566763],\n",
    "                       85:[6.161093716,10.89213895,17.23566763]}, \n",
    "              'combination':{10:[234.0524646,319.4180744,439.586625,445.1743278,538.6709547,628.7931163,344.6212488,437.8395829,593.9066438,442.8460081,539.8044702,620.0304067,720.0891769,833.025738,234.148796],\n",
    "                             15:[120.8605222,164.941802,226.9947003,229.8800904,278.1600826,324.697561,177.9562722,226.0925589,306.6828082,228.6777876,278.7454098,320.1726539,371.8412199,430.1596477,120.910266],\n",
    "                             25:[52.56189381,71.73271574,98.71934288,99.97419076,120.9710206,141.2100362,77.3926714,98.32700418,133.375472,99.45131273,121.2255777,139.2421671,161.712678,187.0751947,52.58352725],\n",
    "                            35:[30.37262348,41.4503856,57.04447108,57.76957856,69.90249009,81.59750251,44.72096224,56.81776015,77.07033936,57.46743614,70.04958463,80.46037934,93.44484998,108.1004515,30.38512425],\n",
    "                            45:[20.16400615,27.51839434,37.87111332,38.35250314,46.40739187,54.17156484,29.68968941,37.72060276,51.16603766,38.15191455,46.5050461,53.41664295,62.03687116,71.76654231,20.17230526],\n",
    "                            55:[14.53858148,19.84121684,27.30569822,27.65278823,33.46049605,39.058593,21.40675645,27.19717762,36.89155825,27.50816054,33.53090636,38.51428184,44.72960876,51.74486237,14.54456527],\n",
    "                            65:[11.07297826,15.11160927,20.79676089,21.06111407,25.48442197,29.74808456,16.30396673,20.71410866,28.09761208,20.9509617,25.53804838,29.33352241,34.06728408,39.41029164,11.07753568],\n",
    "                            75:[11.07297826,15.11160927,20.79676089,21.06111407,25.48442197,29.74808456,16.30396673,20.71410866,28.09761208,20.9509617,25.53804838,29.33352241,34.06728408,39.41029164,11.07753568],\n",
    "                            85:[11.07297826,15.11160927,20.79676089,21.06111407,25.48442197,29.74808456,16.30396673,20.71410866,28.09761208,20.9509617,25.53804838,29.33352241,34.06728408,39.41029164,11.07753568]}}\n",
    "#Dictionary for referring to ACS variables more easily\n",
    "ACS = {'white':'B02001e2','black':'B02001e3','native':'B02001e4',\n",
    "      'asian':'B02001e5','pacific':'B02001e6','other':'B02001e7',\n",
    "      'poverty':'B17021e2','nonwhite':'nonwhite','nonpoverty':'nonpoverty'}\n",
    "#      'renter':'B25008e3','nonrenter':'nonrenter'}\n",
    "#B25008e3\tTOTAL POPULATION IN OCCUPIED HOUSING UNITS BY TENURE: Total: Renter occupied: Total population in occupied housing units -- (Estimate)\n",
    "demos = list(ACS.keys())   \n",
    "\n",
    "# #FIPS <-> names only needed for Tableau plotting\n",
    "# county_names = pandas.read_csv(root+\"\\\\FIPS names.csv\")\n",
    "# county_names['county_FIPS'] = county_names.apply(lambda row: str(row['county_FIPS']), axis=1 )\n",
    "# county_names['county_FIPS'] = county_names.apply(lambda row: '0'+row['county_FIPS'] \n",
    "#                                                  if len(row['county_FIPS'])<5 \n",
    "#                                                  else row['county_FIPS'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a300c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts AADT for passenger, combination, and single trucks for a road\n",
    "#into number of passenger car equivalents (NPCE) based on speed on road\n",
    "def npce(aadt_c,aadt_s,aadt_p,speed):\n",
    "    \n",
    "    #Match the speed in HPMS to the closest speed in the npce dictionary\n",
    "    key = [i for i in speed_npce['single'].keys()]\n",
    "    key_dif = [abs(i-speed) for i in key]\n",
    "    speed = key[key_dif.index(min(key_dif))]\n",
    "    \n",
    "    aadt_c_npce = [aadt_c*i*j for i,j in \n",
    "                   zip(veh_class['combination'],speed_npce['combination'][speed])]\n",
    "    aadt_s_npce = [aadt_s*i*j for i,j in \n",
    "                   zip(veh_class['single'],speed_npce['single'][speed])]\n",
    "    aadt_npce = sum([aadt_p]+aadt_c_npce+aadt_s_npce)\n",
    "    return(aadt_npce)\n",
    "\n",
    "\n",
    "#calculate the distance each noise_lvl reaches  (from the ECAT excel tool Noise!AM29)\n",
    "#this equation is derived from Haling and Cohen (1996)\n",
    "def distance(noise_lvl,aadt_npce,speed):\n",
    "    if aadt_npce==0:\n",
    "        return(0)\n",
    "    else:\n",
    "        return( 10**( (noise_lvl - 38.1*log10(speed*1.60934) - 10*log10(aadt_npce/24/speed) -4.095)/-15))\n",
    "                                                                    #speed seemingly should be *1.60934 ? \n",
    "                                                                    #in Haling and Cohen (1996) it is specified this way, the second speed should be in mph\n",
    "#aggregation functions for pandas groupby\n",
    "#div is used to divide the noise damage cost between multiple CBG intersecting a roadway\n",
    "#gath is used to store all of the CBG that intersect a roadway for when aggregating results to a higher regional level\n",
    "def div(x):\n",
    "    return(sum(x)/len(x))\n",
    "def gath(x):\n",
    "    return[i for i in set(x)]\n",
    "\n",
    "#loads housing data for census blocks\n",
    "#constructs x_meter buffer around road segments\n",
    "#finds intersecting census block groups for each road buffer\n",
    "#calculates number of houses in buffer based on (intersection area / census block group area)\n",
    "#adds column for number of houses and road_buffer area to road.shp geopanda_dataframe\n",
    "def est_houses(road,x):\n",
    "    global house_shp\n",
    "    gdb = root+\"\\\\ACS 2019\\\\\"+acs\n",
    "    house = gpd.read_file(gdb, layer=\"X25_Housing_Characteristics\"); house = house.drop('geometry',1)\n",
    "\n",
    "    house = house.rename(columns = {\"GEOID\":\"GEOID_Data\"})\n",
    "    house_shp = pandas.merge(house,c_shp,how='inner',on=['GEOID_Data'])\n",
    "    house_shp = gpd.GeoDataFrame(house_shp)\n",
    "    house_shp['Area'] = house_shp['geometry'].area\n",
    "    keep = ['GEOID_Data','B25001e1','Area','geometry'] #'Shape_Area',\n",
    "    house_shp = house_shp[keep]\n",
    "    \n",
    "    dist = str(int(x/.3048))  #x is passed in meters, name converted to ft\n",
    "    road_bufferX = gpd.GeoDataFrame(road.buffer(x, cap_style=2)) \n",
    "    road_bufferX = road_bufferX.rename(columns={0:'geometry'})\n",
    "    road_bufferX['id'] = road['id']\n",
    "    road_bufferX['rb'+dist+'_area_m'] = road_bufferX['geometry'].area  #area is based on the coordinate units, which is m\n",
    "\n",
    "    c_ = gpd.overlay(road_bufferX,house_shp, how='intersection') \n",
    "    c_['area'] = c_['geometry'].area\n",
    "    c_['houses'+dist] = c_['area']/c_['Area']*c_['B25001e1']  #area is in sq_m\n",
    "    #c_['ratio'+dist] = c_['area']/c_['Area']\n",
    "    \n",
    "    #c_ has more observations than road as some segments intersect multiple census block groups\n",
    "    #then groupby 'Route_ID' summing houses, merge with road by 'id'\n",
    "    c = c_.groupby(c_['id']).aggregate({('houses'+dist):'sum',('rb'+dist+'_area_m'):'first'})#,('ratio'+dist):'first'})\n",
    "    road = pandas.merge(road,c, how='left',on=['id'])\n",
    "    return(road)\n",
    "\n",
    "def latlon(c):    #originally data is in lonlat, some functions require latlon\n",
    "    return((c[1],c[0]))\n",
    "\n",
    "#some HPMS segments have different geometry types (line, multipart, polygon)\n",
    "#coordinate conversion method needs different reference for geometry types\n",
    "def tryconvert(row):\n",
    "    try: \n",
    "        return(int(convert_wgs_to_utm(latlon(row['geometry'].coords[0]))))  #for line\n",
    "    except:\n",
    "        try:\n",
    "            return(int(convert_wgs_to_utm(latlon(row['geometry'].geoms[0].coords[0])))) #for multipart\n",
    "        except:\n",
    "            return(int(convert_wgs_to_utm(latlon(row['geometry'].centroid.coords[0]))))  #for polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d9a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c is an index for the State number in an alphabetical list\n",
    "def equity(c):\n",
    "    global inte, inte_road, county, census, road, inte_census, inte_county, race_shp, road, road_write  #global for testing purposes\n",
    "    global acs, c_shp  #these are global because est_houses uses them, could pass them to the function instead\n",
    "    gc.collect()  #resolves memory issue, failure to overwrite road file for each State\n",
    "    t0=time.time()\n",
    "    acs = files[c]      #the ACS State nomenclature (space, no space, or _) is different than HPMS, so this method requires folders for all states be in ACS\n",
    "    state = house_value['State'][c]   #get the state name as it is refered to in various places\n",
    "    state_utm_zone = STATES_DATA[c][3]\n",
    "    crs_utm = CRS.from_string('epsg:326' + state_utm_zone)  #to facilitate more accurate distances each State's coordinates are converted to a utm zone\n",
    "    \n",
    "    ###################\n",
    "    # 1. Preparing Data\n",
    "    print(state,\"reading files\", end=', ')\n",
    "    #read in polygons of census block groups (cbg)\n",
    "    gdb = root+\"\\\\ACS 2019\\\\\"+acs\n",
    "    c_shp = gpd.read_file(gdb, layer=acs[:-4])\n",
    "    c_shp = c_shp.to_crs(crs_utm)\n",
    "    \n",
    "    #race and poverty demographics of cbg\n",
    "    #load and merge with geometry in c_shp\n",
    "    race = gpd.read_file(gdb, layer=\"X02_Race\"); race = race.drop('geometry',1)\n",
    "    poverty = gpd.read_file(gdb, layer=\"X17_Poverty\"); poverty = poverty.drop('geometry',1)\n",
    "    race = pandas.merge(race,poverty,how='inner',on='GEOID')\n",
    "    race['nonwhite'] = race['B02001e1'] - race[ACS['white']]\n",
    "    race['nonpoverty'] = race['B02001e1'] - race[ACS['poverty']] #could automate these non_steps depending on how many\n",
    "    race = race.rename(columns = {\"GEOID\":\"GEOID_Data\"})\n",
    "    race_shp = pandas.merge(race,c_shp,how='inner',on=['GEOID_Data'])\n",
    "    race_shp['county_FIPS'] = race_shp.apply(lambda row: row['GEOID'][0:5], axis=1)\n",
    "    race_shp['tract_FIPS'] = race_shp.apply(lambda row: row['GEOID'][2:-1], axis=1)\n",
    "    \n",
    "    \n",
    "#     house = gpd.read_file(gdb, layer=\"X25_Housing_Characteristics\"); house = house.drop('geometry',1)\n",
    "#     house = house.rename(columns = {\"GEOID\":\"GEOID_Data\"})\n",
    "#     keep = ['GEOID_Data','B25001e1']\n",
    "#     house = house[keep]\n",
    "#     race_shp = pandas.merge(race_shp,house,how=\"inner\",on=['GEOID_Data'])\n",
    "#     state_hh_size = sum(race_shp[])\n",
    "        \n",
    "    #road file for the state\n",
    "    #gdb = root+\"\\\\state shp\\\\\"+state+\".shp\"\n",
    "    gdb = root+\"\\\\state shp\\\\\"+state+\".shp\"\n",
    "    road = gpd.read_file(gdb)\n",
    "    road = road[road['geometry'] != None]\n",
    "    road['id'] = road.index\n",
    "    renames = {i:i.upper() for i in road.columns}    #HPMS 2016 and 2017 use different naming conventions\n",
    "    renames['geometry'] = 'geometry'\n",
    "    \n",
    "    #some cleanup on column types\n",
    "    road['ROUTE_ID'] = road.apply(lambda row: str(row['ROUTE_ID']), axis=1)\n",
    "    change = ['F_SYSTEM','AADT','AADT_SINGL','AADT_COMBI','SPEED_LIMI']\n",
    "    for i in change:\n",
    "        road[i] = road[i].apply(int)\n",
    "    \n",
    "    road['AADT_PASSENGER'] = road['AADT'] - road['AADT_COMBI'] - road['AADT_SINGL']\n",
    "    \n",
    "    #sets speed limit for roads without entry. based on avg speed for these road types\n",
    "    typ_sp = {0:45,1:65,2:55,3:45,4:45,5:35,6:30,7:25}\n",
    "    typ = list(set(road['F_SYSTEM']))\n",
    "    typ.sort()\n",
    "    road['SPEED_LIMI'] = road['SPEED_LIMI'].fillna(0)\n",
    "    for i in typ:\n",
    "        road['SPEED_LIMI'][(road['F_SYSTEM']==i) & \n",
    "                           ((road['SPEED_LIMI']==0) | (road['SPEED_LIMI']>90))] = typ_sp[i]\n",
    "        \n",
    "    #attribute AADT to vehicle classes\n",
    "    #as their NPCE varies with speed differently\n",
    "    road['AADT_NPCE'] = road.apply(lambda row : npce(row['AADT_COMBI'],\n",
    "                        row['AADT_SINGL'],row['AADT_PASSENGER'],\n",
    "                        row['SPEED_LIMI']), axis=1)\n",
    "        \n",
    "    road = road.to_crs(crs_utm)\n",
    "    road['length'] = road.length/1609.34  #length is in miles and crs is in meters\n",
    "    \n",
    "    ############################\n",
    "    #2. Estimate Housing Density\n",
    "    print(\"housing density\", end=', ')\n",
    "    \n",
    "    ## Count the number of houses in each buffer strip from the road\n",
    "    dist = [50,300,1000]  #in ft, UTM is in m\n",
    "    for d in dist:\n",
    "        #t0=time.time()\n",
    "        road = est_houses(road,d*.3048)\n",
    "        road['houses'+str(d)] = road['houses'+str(d)].fillna(0)\n",
    "        road['rb'+str(d)+'_area_m'] = road['rb'+str(d)+'_area_m'].fillna(1)\n",
    "        #print(d,time.time()-t0)\n",
    "        \n",
    "    #convert the buffer strip areas from meters to feet\n",
    "    road['rb1000_area_ft'] = road['rb1000_area_m']/(.3048**2)\n",
    "    road['rb300_area_ft'] = road['rb300_area_m']/(.3048**2)\n",
    "    road['rb50_area_ft'] = road['rb50_area_m']/(.3048**2)\n",
    "    \n",
    "    #subtract the houses/area from smaller buffer, since the larger contains the smaller\n",
    "    #want the number of houses/area in the buffer_strip\n",
    "    road['h1000_all'] = road['houses1000']\n",
    "    road['houses1000'] = road['houses1000'] - road['houses300']\n",
    "    road['houses300'] = road['houses300'] - road['houses50']\n",
    "    road['rb1000_area_ft'] = road['rb1000_area_ft'] - road['rb300_area_ft']\n",
    "    road['rb300_area_ft'] = road['rb300_area_ft'] - road['rb50_area_ft']\n",
    "    \n",
    "    for d in dist:\n",
    "        road['rb'+str(d)+'_area_ft'] = road['rb'+str(d)+'_area_ft'].replace(0,1)\n",
    "        #some values have zero area after the subtraction due to buffer overlay being the same area\n",
    "        #alternatively could replace null or inf density values with 0\n",
    "        #replacing it with 1 is not the true buffer area, but removes the issue of dividing by 0\n",
    "        #this should only arise for buffers on edge or that don't intersect any ACS, like roads outside State boundary\n",
    "\n",
    "    #housing density is houses per square mile in the buffer_strip\n",
    "    ## we then take the width affected by each noise_range\n",
    "    # and use it to estimate how many houses are affected at that distance\n",
    "    road['HD_50'] = road['houses50'] / (road['rb50_area_ft']/5280**2)\n",
    "    road['HD_300'] = road['houses300'] / (road['rb300_area_ft']/5280**2)\n",
    "    road['HD_1000'] = road['houses1000'] / (road['rb1000_area_ft']/5280**2)\n",
    "\n",
    "\n",
    "    ########################\n",
    "    #3. Estimate Noise Level\n",
    "    print(\"noise \", end=', ')\n",
    "    \n",
    "    #iterates over noise levels and calculates the max distance those levels affect given the traffic and speed\n",
    "    for i in range(55,85,5):\n",
    "        road[str(i)+\"_dBA_dist\"] = road.apply(lambda row : distance(i,row['AADT_NPCE'],row['SPEED_LIMI']),axis=1)\n",
    "    \n",
    "    # calculate buffer_strip for each maximum noise level\n",
    "    # the buffer_strip is the distance between each dBA_dist, the width of the area affected by that noise range\n",
    "    for i in range(60,85,5):\n",
    "        road[\"buffer_\"+str(i-5)+\"_\"+str(i)] = road.apply(lambda row: row[str(i-5)+'_dBA_dist']\n",
    "                                                       - row[str(i)+'_dBA_dist'],axis=1)\n",
    "    road[\"buffer_>80\"] = road.apply(lambda row: row['80_dBA_dist']-30 if row['80_dBA_dist']>30 else 0, axis=1)\n",
    "\n",
    "    road = road.fillna(0)\n",
    "\n",
    "    #calculate the number of housing units per road mile at each max noise level\n",
    "    # noise_distance_ft * both_sides / (ft/mile) * housing_density_sq_mile = houses/mile\n",
    "    for i in range(60,85,5):\n",
    "        road['houses_per_mile_'+str(i-5)+\"_\"+str(i)] = road.apply(lambda row:\n",
    "    row[\"buffer_\"+str(i-5)+\"_\"+str(i)]*2/5280*row['HD_50'] if row[\"buffer_\"+str(i-5)+\"_\"+str(i)]<50 else ( \n",
    "    row[\"buffer_\"+str(i-5)+\"_\"+str(i)]*2/5280*row['HD_300'] if row[\"buffer_\"+str(i-5)+\"_\"+str(i)]<300 else \n",
    "    row[\"buffer_\"+str(i-5)+\"_\"+str(i)]*2/5280*row['HD_1000'] ), axis=1)\n",
    "\n",
    "    road['houses_per_mile_>80'] = road.apply(lambda row:\n",
    "    row[\"buffer_>80\"]*2/5280*row['HD_50'] if row[\"buffer_\"+str(i-5)+\"_\"+str(i)]<50 else ( \n",
    "    row[\"buffer_>80\"]*2/5280*row['HD_300'] if row[\"buffer_\"+str(i-5)+\"_\"+str(i)]<300 else \n",
    "    row[\"buffer_>80\"]*2/5280*row['HD_1000'] ), axis=1)\n",
    "    \n",
    "    # calculate the noise damage cost\n",
    "    # houses/mile * noise_effect * housing_value_change_per_noise * road_miles = housing_value_change\n",
    "    for i in range(60,85,5):\n",
    "        road['dmg_'+str(i-5)+\"_\"+str(i)] = road.apply(lambda row: \n",
    "                row['houses_per_mile_'+str(i-5)+\"_\"+str(i)]*(i-57.5)*hv[state]*row['length'], axis=1)\n",
    "    road['dmg_>80'] = road.apply(lambda row: row['houses_per_mile_>80']*27.5*hv[state]*row['length'], axis=1)\n",
    "    road['dmg'] = road.apply(lambda row: row['dmg_55_60']+row['dmg_60_65']+row['dmg_65_70']+\n",
    "                            row['dmg_70_75']+row['dmg_75_80']+row['dmg_>80'],axis=1)\n",
    "\n",
    "    #############################\n",
    "    #4. Attribute to Demographics\n",
    "    #     State and National\n",
    "    print(\"attribute to demos \")\n",
    "    #attribute dmg to each demographic for intersecting census block groups\n",
    "    #keep track of sum of dmg to each demographic\n",
    "    #at end compare % of dmg received to population share\n",
    "\n",
    "    road = gpd.GeoDataFrame(road)\n",
    "    \n",
    "    #This method of intersection doesn't account for census block group intersecting the buffer but not the road\n",
    "    inte = gpd.sjoin(race_shp,road, op='intersects')\n",
    "    \n",
    "    agg_functions ={'B02001e1':'sum','dmg':'first','county_FIPS':gath,'tract_FIPS':gath,'GEOID':gath,\n",
    "                   'URBAN_CODE':'first'}    \n",
    "    for i in demos:\n",
    "        agg_functions[ACS[i]] = 'sum'\n",
    "    inte_road = inte.groupby(inte['index_right']).aggregate(agg_functions)\n",
    "    #this method ensures each road is counted once, while summing up the populations of the intersecting CBGs\n",
    "    #essentially forming 'super CBGs' of all the CBGs intersecting a road in order the calculate the share of each demographic population\n",
    "    #later, when aggregating over larger areas the dmg for each road segment is divided by the number of intersecting CBGs to ensure all dmg is only counted once\n",
    "\n",
    "    inte_road = inte_road.fillna(0)  \n",
    "    \n",
    "    #split the noise dmg for each road segment into demographics based on share of population\n",
    "    for i in demos:\n",
    "        inte_road[i+'_dmg'] = inte_road[ACS[i]] / inte_road['B02001e1'] * inte_road['dmg']\n",
    "    \n",
    "    inte_road = inte_road.fillna(0)\n",
    "    \n",
    "    ################### For writing road.shp with noise dmg estimates ###################\n",
    "#     keep = ['YEAR_RECOR','STATE_CODE','ROUTE_ID','BEGIN_POIN','END_POINT','ROUTE_NUMB','ROUTE_NAME',\n",
    "#        'F_SYSTEM','FACILITY_T','NHS','THROUGH_LA','SPEED_LIMI','AADT','AADT_COMBI','AADT_SINGL','AADT_NPCE',\n",
    "#        'Shape_Leng','length','geometry','HD_50','HD_300','HD_1000']\n",
    "#     keep = ['STATE_CODE','ROUTE_ID','ROUTE_NUMB','F_SYSTEM','FACILITY_T','URBAN_CODE',\n",
    "#             'SPEED_LIMI','AADT','AADT_PASSENGER','AADT_COMBI','AADT_SINGL','AADT_NPCE',\n",
    "#             'length','geometry','HD_50','HD_300','HD_1000','h1000_all']\n",
    "#     road_write = road[keep]\n",
    "#     road_write['index_right'] = road_write.index\n",
    "#     road_write = pandas.merge(inte_road,road_write,how='inner',on=['index_right'])\n",
    "#     road_write = gpd.GeoDataFrame(road_write)\n",
    "#     road_write['county_FIPS'] = road_write.apply(lambda row: str(row['county_FIPS']), axis=1 )\n",
    "#     road_write['tract_FIPS'] = road_write.apply(lambda row: str(row['tract_FIPS']), axis=1 )\n",
    "#     road_write['GEOID'] = road_write.apply(lambda row: str(row['GEOID']), axis=1 )\n",
    "#     rname = {'B02001e1':'total_pop','URBAN_CODE_y':'URBAN_CODE'}\n",
    "#     for i in demos:\n",
    "#         rname[ACS[i]] = i+'_pop'\n",
    "#     road_write = road_write.rename(columns=rname)\n",
    "#     #Having issues with to_file(*.shp) filling out too many decimal places\n",
    "#     road_write['dmg_length'] = road_write['dmg']/road_write['length']/10  #dmg per 1/10 mile\n",
    "#     road_write['dmg_length'] = road_write.apply(lambda row: int(row['dmg_length']), axis=1)\n",
    "#     #keep = ['ROUTE_NUMB','F_SYSTEM','dmg_length','geometry']\n",
    "    \n",
    "#     keep_csv = ['STATE_CODE','county_FIPS','tract_FIPS','GEOID','URBAN_CODE',\n",
    "#                 'ROUTE_NUMB','F_SYSTEM','FACILITY_T', \n",
    "#                 'AADT_PASSENGER','AADT_SINGL','AADT_COMBI','AADT_NPCE','SPEED_LIMI', \n",
    "#                 'dmg','dmg_length','length','total_pop','h1000_all',\n",
    "#                 'HD_50','HD_300','HD_1000']\n",
    "#     for i in demos:\n",
    "#         keep_csv.append(i+\"_pop\")\n",
    "#         keep_csv.append(i+\"_dmg\")\n",
    "#     road_write_csv = pandas.DataFrame(road_write[keep_csv])\n",
    "#     for i in demos:\n",
    "#         road_write_csv[i+\"_house\"] = road_write_csv['h1000_all']*road_write_csv[i+\"_pop\"]/road_write_csv['total_pop']\n",
    "#         road_write_csv[i+\"_dmg_per_house\"] = road_write_csv[i+\"_dmg\"]/road_write_csv[i+\"_house\"]\n",
    "#     root_out_csv =r\"\"\n",
    "# #     road_write_csv.to_csv(root_out_csv+\"\\\\\"+state+\"_noise_dmg.csv\")  #use separate program to combine States\n",
    "    \n",
    "#     keep = ['STATE_CODE','county_FIPS','tract_FIPS','GEOID','URBAN_CODE',\n",
    "#                 'ROUTE_NUMB','F_SYSTEM','FACILITY_T', \n",
    "#                 'AADT_PASSENGER','AADT_SINGL','AADT_COMBI','AADT_NPCE','SPEED_LIMI', \n",
    "#                 'dmg','dmg_length','length','total_pop','h1000_all',\n",
    "#                 'HD_50','HD_300','HD_1000','geometry']\n",
    "#     for i in demos:\n",
    "#         keep.append(i+\"_pop\")\n",
    "#         keep.append(i+\"_dmg\")\n",
    "#     road_write = road_write[keep]\n",
    "#     road_write = road_write.to_crs(\"epsg:4326\")\n",
    "#     root_out = r\"\"\n",
    "#     road_write.to_file(root_out+\"\\\\\"+state+\"_noise_dmg.shp\")\n",
    "    ###################                                               ###################\n",
    "    \n",
    "    \n",
    "    result['state'].append(state)\n",
    "    result['state_pop'].append( sum(race_shp['B02001e1']))\n",
    "    result['state_dmg'].append( sum(inte_road['dmg']) )\n",
    "    for i in demos:\n",
    "        result[i+\"_pop\"].append( sum(race_shp[ACS[i]]) )\n",
    "        result[i+'_dmg'].append( sum(inte_road[i+'_dmg']))\n",
    "    result['rural_dmg'].append( sum(inte_road[inte_road['URBAN_CODE']==99999]['dmg']))\n",
    "    result['urban_dmg'].append( sum(inte_road[inte_road['URBAN_CODE']!=99999]['dmg']))\n",
    "    \n",
    "    \n",
    "    #This section prints out the noise-equity ratios for the state\n",
    "    print(\"\\nState: \", state, \n",
    "          \" Time: \",round(time.time() - t0,2), sep='')\n",
    "    print(\"-------------------\")\n",
    "    print(\"White\")\n",
    "    print(round(sum(inte_road['white_dmg']) / sum(inte_road['dmg']),4),'dmg')\n",
    "    print(round(sum(race_shp['B02001e2']) / sum(race_shp['B02001e1']),4),'pop')\n",
    "\n",
    "    print(\"Black\")\n",
    "    print(round(sum(inte_road['black_dmg']) / sum(inte_road['dmg']),4))\n",
    "    print(round(sum(race_shp['B02001e3']) / sum(race_shp['B02001e1']),4))\n",
    "\n",
    "    print(\"Native\")\n",
    "    print(round(sum(inte_road['native_dmg']) / sum(inte_road['dmg']),4))\n",
    "    print(round(sum(race_shp['B02001e4']) / sum(race_shp['B02001e1']),4))\n",
    "\n",
    "    print(\"Asian\")\n",
    "    print(round(sum(inte_road['asian_dmg']) / sum(inte_road['dmg']),4))\n",
    "    print(round(sum(race_shp['B02001e5']) / sum(race_shp['B02001e1']),4))\n",
    "    \n",
    "    print(\"Pacific\")\n",
    "    print(round(sum(inte_road['pacific_dmg']) / sum(inte_road['dmg']),4))\n",
    "    print(round(sum(race_shp['B02001e6']) / sum(race_shp['B02001e1']),4))\n",
    "    \n",
    "    print(\"Other\")\n",
    "    print(round(sum(inte_road['other_dmg']) / sum(inte_road['dmg']),4))\n",
    "    print(round(sum(race_shp['B02001e7']) / sum(race_shp['B02001e1']),4))\n",
    "    \n",
    "\n",
    "    #############################\n",
    "    #5. Attribute to Demographics\n",
    "    #    County and Census Tract\n",
    "    \n",
    "    #below avoids multi-counting for roads that intersect multiple counties/census tracts, \n",
    "    # dmg needs to be divided since the summation is across counties/census tracts when reaggregated\n",
    "    # assumes dmg is split between intersecting counties/census tracts [in revision will split based on proportion of road intersecting]\n",
    "    inte_road['dmg'] = inte_road['dmg'] / inte_road.apply(lambda row: len(row['GEOID']), axis=1)\n",
    "    for i in demos:\n",
    "        inte_road[i+'_dmg'] = inte_road[i+'_dmg'] / inte_road.apply(lambda row: len(row['GEOID']), axis=1)\n",
    "    inte_road['index_right'] = inte_road.index\n",
    "    inte_road.index.name = 'id'\n",
    "    inte_road = inte_road.rename(columns={'dmg':'total_dmg'})   #to distinguish it for remerge\n",
    "    keep = ['index_right','total_dmg']#'nonwhite_dmg'\n",
    "    for i in demos:\n",
    "        keep.append(i+'_dmg')   #don't need 'road_block' population counts, those were used only for proportion of dmg allocation\n",
    "    inte_road = inte_road[keep]\n",
    "    ######  ** ##\n",
    "    keep_inte = ['county_FIPS','tract_FIPS','GEOID','index_right']\n",
    "    inte = inte[keep_inte]   #to simplify dataframe for later steps\n",
    "    inte_ = pandas.merge(inte,inte_road, how='inner',on=['index_right']) \n",
    "    \n",
    "    agg_functions = {'total_dmg':'sum'}#, 'nonwhite_dmg':'sum'} #just to count the damage groups\n",
    "    for i in demos:\n",
    "        agg_functions[i+'_dmg'] = 'sum'\n",
    "    \n",
    "    inte_county = inte_.groupby(inte_['county_FIPS']).aggregate(agg_functions)\n",
    "    inte_county['county_FIPS'] = inte_county.index\n",
    "    inte_county.index.names = ['id']\n",
    "    \n",
    "    agg_pop = {'B02001e1':'sum'} #just to count the population groups\n",
    "    for i in demos:\n",
    "        agg_pop[ACS[i]] = 'sum'\n",
    "    county_shp = race_shp.groupby(race_shp['county_FIPS']).aggregate(agg_pop)\n",
    "    \n",
    "    #inte_county has the correct damage for each, county_shp has the correct population\n",
    "    inte_county = pandas.merge(inte_county,county_shp, how='inner',on=['county_FIPS'])\n",
    "    \n",
    "    rname = {'B02001e1':'total_pop'}\n",
    "    for i in demos:\n",
    "        rname[ACS[i]] = i+'_pop'\n",
    "    inte_county = inte_county.rename(columns=rname)\n",
    "    inte_county = inte_county.fillna(0)\n",
    "    \n",
    "    #calculate the noise-equity ratios (called ndp here for noise% divided by population%)\n",
    "    for i in demos:\n",
    "        inte_county[i+'_ndp'] = inte_county[i+'_dmg']/inte_county['total_dmg'] / (inte_county[i+'_pop']/inte_county['total_pop'])\n",
    "    inte_county = inte_county.fillna(0)\n",
    "    keep = ['county_FIPS','name']#,'white_ndp','black_ndp','native_ndp','asian_ndp','pacific_ndp','other_ndp']\n",
    "    for i in demos:\n",
    "        keep.append(i+'_ndp')  \n",
    "        keep.append(i+'_dmg')\n",
    "        keep.append(i+'_pop')\n",
    "    #keep.append('nonwhite_ndp')\n",
    "    inte_county = pandas.merge(inte_county,county_names,how='inner',on='county_FIPS')\n",
    "    \n",
    "    inte_county_ = inte_county[keep]\n",
    "#     root_out = r\"\"\n",
    "#     inte_county_.to_csv(root_out+\"\\\\\"+state+\"_noise_dmg_equity_county.csv\")\n",
    "    \n",
    "    #add county names\n",
    "    \n",
    "    inte_county2 = pandas.melt(inte_county_,id_vars=['county_FIPS','name'],var_name='metrics',value_name='values')\n",
    "    inte_county2[\"Demographic\"] = inte_county2.apply(lambda row: row['metrics'][:-4], axis=1)\n",
    "    inte_county2['metrics'] = inte_county2.apply(lambda row: row['metrics'][-3:], axis=1)\n",
    "    if c==0:\n",
    "        county= pandas.DataFrame(columns=list(inte_county2.columns))\n",
    "    county = pandas.concat([county,inte_county2])\n",
    "    \n",
    "    ###################\n",
    "    ##### Census  #####\n",
    "    inte_census = inte_road.groupby(inte_['tract_FIPS']).aggregate(agg_functions)\n",
    "    inte_census['tract_FIPS'] = inte_census.index\n",
    "    inte_census.index.names = ['id']\n",
    "    \n",
    "    census_shp = race_shp.groupby(race_shp['tract_FIPS']).aggregate(agg_pop)\n",
    "    \n",
    "    #inte_census has the correct damage for each, census_shp has the correct population\n",
    "    inte_census = pandas.merge(inte_census,census_shp, how='inner',on=['tract_FIPS'])\n",
    "    \n",
    "    inte_census = inte_census.rename(columns=rname)\n",
    "#     inte_census = inte_census.rename(columns={'B02001e1':'total_pop','B02001e2':'white_pop','B02001e3':'black_pop',\n",
    "#                       'B02001e4':'native_pop','B02001e5':'asian_pop','B02001e6':'pacific_pop',\n",
    "#                       'B02001e7':'other_pop', 'dmg':'total_dmg' })\n",
    "    inte_census = inte_census.fillna(0)\n",
    "    \n",
    "    for i in demos:\n",
    "        inte_census[i+'_ndp'] = inte_census[i+'_dmg']/inte_census['total_dmg'] / (inte_census[i+'_pop']/inte_census['total_pop'])\n",
    "    inte_census = inte_census.fillna(0)\n",
    "    #inte_census['nonwhite'+'_ndp'] = inte_census['nonwhite'+'_dmg']/inte_census['total_dmg'] / (inte_census['nonwhite'+'_pop']/inte_census['total_pop'])\n",
    "    keep = ['tract_FIPS']#,'white_ndp','black_ndp','native_ndp','asian_ndp','pacific_ndp','other_ndp']\n",
    "    for i in demos:\n",
    "        keep.append(i+'_ndp')\n",
    "        keep.append(i+'_dmg')\n",
    "        keep.append(i+'_pop')\n",
    "    #keep.append('nonwhite_ndp')\n",
    "    inte_census_ = inte_census[keep]\n",
    "#     root_out = r\"\"\n",
    "#     inte_census_.to_csv(root_out+\"\\\\\"+state+\"_noise_dmg_equity_census.csv\")\n",
    "    \n",
    "#     race_shp_ = race_shp[['TRACTCE','geometry']]  #merging for geometry\n",
    "#     # ! #  need census tract geometry--NOT census block geometry\n",
    "#     inte_census_ = pandas.merge(inte_census_,race_shp_,how='inner',on=['TRACTCE'])\n",
    "    \n",
    "    inte_census2 = pandas.melt(inte_census_,id_vars=['tract_FIPS'],var_name='metrics',value_name='values')\n",
    "    inte_census2[\"Demographic\"] = inte_census2.apply(lambda row: row['metrics'][:-4], axis=1)\n",
    "    inte_census2['metrics'] = inte_census2.apply(lambda row: row['metrics'][-3:], axis=1)\n",
    "    if c==0:\n",
    "        census= pandas.DataFrame(columns=list(inte_census2.columns))\n",
    "    census = pandas.concat([census,inte_census2])\n",
    "    \n",
    "    print(\"Total time:\",round((time.time()-t0)/60,1),\"mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f6e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block must be run before equity is called to set up the results storage\n",
    "#National/State results will be stored in result\n",
    "#County and Census Tract are stored separately\n",
    "result = {'state':[], 'state_pop':[]}\n",
    "for i in demos:\n",
    "    result[i+'_pop'] = []\n",
    "result['state_dmg'] = []\n",
    "for i in demos:\n",
    "    result[i+'_dmg'] = []\n",
    "result['rural_dmg'] = []\n",
    "result['urban_dmg'] = []\n",
    "county= pandas.DataFrame()     \n",
    "census = pandas.DataFrame()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16bfae83",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Alabama Time: 1150.94\n",
      "-------------------\n",
      "White\n",
      "0.5401 dmg\n",
      "0.6809 pop\n",
      "Black\n",
      "0.3991\n",
      "0.2664\n",
      "Native\n",
      "0.0034\n",
      "0.0052\n",
      "Asian\n",
      "0.02\n",
      "0.0136\n",
      "Pacific\n",
      "0.0004\n",
      "0.0005\n",
      "Other\n",
      "0.0178\n",
      "0.0145\n",
      "Total time: 19.6 mins\n",
      "Alaska reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Alaska Time: 19157.65\n",
      "-------------------\n",
      "White\n",
      "0.5906 dmg\n",
      "0.6458 pop\n",
      "Black\n",
      "0.0543\n",
      "0.0328\n",
      "Native\n",
      "0.1037\n",
      "0.1489\n",
      "Asian\n",
      "0.0992\n",
      "0.0623\n",
      "Pacific\n",
      "0.023\n",
      "0.0125\n",
      "Other\n",
      "0.0248\n",
      "0.0153\n",
      "Total time: 320.1 mins\n",
      "Arizona reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Arizona Time: 1166.7\n",
      "-------------------\n",
      "White\n",
      "0.7593 dmg\n",
      "0.7722 pop\n",
      "Black\n",
      "0.0547\n",
      "0.045\n",
      "Native\n",
      "0.0279\n",
      "0.045\n",
      "Asian\n",
      "0.0395\n",
      "0.0331\n",
      "Pacific\n",
      "0.0027\n",
      "0.0021\n",
      "Other\n",
      "0.0762\n",
      "0.0653\n",
      "Total time: 19.6 mins\n",
      "Arkansas reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Arkansas Time: 1204.89\n",
      "-------------------\n",
      "White\n",
      "0.6352 dmg\n",
      "0.7672 pop\n",
      "Black\n",
      "0.2758\n",
      "0.1532\n",
      "Native\n",
      "0.0067\n",
      "0.0068\n",
      "Asian\n",
      "0.0184\n",
      "0.0152\n",
      "Pacific\n",
      "0.0025\n",
      "0.0029\n",
      "Other\n",
      "0.0305\n",
      "0.0279\n",
      "Total time: 20.3 mins\n",
      "California reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: California Time: 3893.09\n",
      "-------------------\n",
      "White\n",
      "0.5555 dmg\n",
      "0.597 pop\n",
      "Black\n",
      "0.0689\n",
      "0.0579\n",
      "Native\n",
      "0.0067\n",
      "0.0077\n",
      "Asian\n",
      "0.1706\n",
      "0.1449\n",
      "Pacific\n",
      "0.004\n",
      "0.004\n",
      "Other\n",
      "0.1442\n",
      "0.1395\n",
      "Total time: 65.8 mins\n",
      "Colorado reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Colorado Time: 1627.63\n",
      "-------------------\n",
      "White\n",
      "0.8094 dmg\n",
      "0.84 pop\n",
      "Black\n",
      "0.0532\n",
      "0.0416\n",
      "Native\n",
      "0.0097\n",
      "0.0098\n",
      "Asian\n",
      "0.0408\n",
      "0.0318\n",
      "Pacific\n",
      "0.0016\n",
      "0.0015\n",
      "Other\n",
      "0.0431\n",
      "0.0386\n",
      "Total time: 27.3 mins\n",
      "Connecticut reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Connecticut Time: 276.79\n",
      "-------------------\n",
      "White\n",
      "0.6544 dmg\n",
      "0.7592 pop\n",
      "Black\n",
      "0.1589\n",
      "0.1072\n",
      "Native\n",
      "0.0033\n",
      "0.0028\n",
      "Asian\n",
      "0.0608\n",
      "0.0451\n",
      "Pacific\n",
      "0.0005\n",
      "0.0003\n",
      "Other\n",
      "0.0829\n",
      "0.0521\n",
      "Total time: 4.7 mins\n",
      "Delaware reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Delaware Time: 159.54\n",
      "-------------------\n",
      "White\n",
      "0.6184 dmg\n",
      "0.6876 pop\n",
      "Black\n",
      "0.2783\n",
      "0.2218\n",
      "Native\n",
      "0.0033\n",
      "0.0039\n",
      "Asian\n",
      "0.0508\n",
      "0.0387\n",
      "Pacific\n",
      "0.0004\n",
      "0.0006\n",
      "Other\n",
      "0.0224\n",
      "0.0192\n",
      "Total time: 2.7 mins\n",
      "District reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: District Time: 110.23\n",
      "-------------------\n",
      "White\n",
      "0.4908 dmg\n",
      "0.4127 pop\n",
      "Black\n",
      "0.3758\n",
      "0.4631\n",
      "Native\n",
      "0.0033\n",
      "0.003\n",
      "Asian\n",
      "0.0519\n",
      "0.0398\n",
      "Pacific\n",
      "0.0012\n",
      "0.0005\n",
      "Other\n",
      "0.044\n",
      "0.0498\n",
      "Total time: 1.9 mins\n",
      "Florida reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Florida Time: 1752.58\n",
      "-------------------\n",
      "White\n",
      "0.7144 dmg\n",
      "0.7512 pop\n",
      "Black\n",
      "0.1875\n",
      "0.1607\n",
      "Native\n",
      "0.0024\n",
      "0.0028\n",
      "Asian\n",
      "0.0295\n",
      "0.0273\n",
      "Pacific\n",
      "0.0007\n",
      "0.0006\n",
      "Other\n",
      "0.0371\n",
      "0.0299\n",
      "Total time: 29.6 mins\n",
      "Georgia reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Georgia Time: 2032.36\n",
      "-------------------\n",
      "White\n",
      "0.4717 dmg\n",
      "0.5862 pop\n",
      "Black\n",
      "0.4018\n",
      "0.3161\n",
      "Native\n",
      "0.006\n",
      "0.0036\n",
      "Asian\n",
      "0.0584\n",
      "0.0398\n",
      "Pacific\n",
      "0.0008\n",
      "0.0006\n",
      "Other\n",
      "0.0315\n",
      "0.0281\n",
      "Total time: 34.2 mins\n",
      "Hawaii reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Hawaii Time: 1554.55\n",
      "-------------------\n",
      "White\n",
      "0.2087 dmg\n",
      "0.2495 pop\n",
      "Black\n",
      "0.0249\n",
      "0.0183\n",
      "Native\n",
      "0.0016\n",
      "0.0026\n",
      "Asian\n",
      "0.4748\n",
      "0.3779\n",
      "Pacific\n",
      "0.0772\n",
      "0.1006\n",
      "Other\n",
      "0.0119\n",
      "0.0123\n",
      "Total time: 26.1 mins\n",
      "Idaho reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Idaho Time: 1991.95\n",
      "-------------------\n",
      "White\n",
      "0.8936 dmg\n",
      "0.8997 pop\n",
      "Black\n",
      "0.0091\n",
      "0.0069\n",
      "Native\n",
      "0.011\n",
      "0.0135\n",
      "Asian\n",
      "0.018\n",
      "0.0141\n",
      "Pacific\n",
      "0.0015\n",
      "0.0016\n",
      "Other\n",
      "0.0359\n",
      "0.0347\n",
      "Total time: 33.3 mins\n",
      "Illinois reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Illinois Time: 1750.8\n",
      "-------------------\n",
      "White\n",
      "0.6286 dmg\n",
      "0.7153 pop\n",
      "Black\n",
      "0.1916\n",
      "0.142\n",
      "Native\n",
      "0.003\n",
      "0.0026\n",
      "Asian\n",
      "0.0886\n",
      "0.0547\n",
      "Pacific\n",
      "0.0004\n",
      "0.0004\n",
      "Other\n",
      "0.0554\n",
      "0.0593\n",
      "Total time: 29.6 mins\n",
      "Indiana reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Indiana Time: 1337.06\n",
      "-------------------\n",
      "White\n",
      "0.7405 dmg\n",
      "0.8331 pop\n",
      "Black\n",
      "0.169\n",
      "0.094\n",
      "Native\n",
      "0.0027\n",
      "0.0024\n",
      "Asian\n",
      "0.0263\n",
      "0.0228\n",
      "Pacific\n",
      "0.0003\n",
      "0.0004\n",
      "Other\n",
      "0.0316\n",
      "0.0219\n",
      "Total time: 22.7 mins\n",
      "Iowa reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Iowa Time: 6972.85\n",
      "-------------------\n",
      "White\n",
      "0.8379 dmg\n",
      "0.9002 pop\n",
      "Black\n",
      "0.0702\n",
      "0.0371\n",
      "Native\n",
      "0.0043\n",
      "0.0038\n",
      "Asian\n",
      "0.0397\n",
      "0.0241\n",
      "Pacific\n",
      "0.0012\n",
      "0.0012\n",
      "Other\n",
      "0.0192\n",
      "0.0124\n",
      "Total time: 117.8 mins\n",
      "Kansas reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Kansas Time: 3077.59\n",
      "-------------------\n",
      "White\n",
      "0.7899 dmg\n",
      "0.8438 pop\n",
      "Black\n",
      "0.0859\n",
      "0.0585\n",
      "Native\n",
      "0.0083\n",
      "0.0082\n",
      "Asian\n",
      "0.0397\n",
      "0.0295\n",
      "Pacific\n",
      "0.0008\n",
      "0.0008\n",
      "Other\n",
      "0.0321\n",
      "0.0246\n",
      "Total time: 51.7 mins\n",
      "Kentucky reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Kentucky Time: 2406.99\n",
      "-------------------\n",
      "White\n",
      "0.7906 dmg\n",
      "0.8695 pop\n",
      "Black\n",
      "0.137\n",
      "0.0807\n",
      "Native\n",
      "0.002\n",
      "0.0021\n",
      "Asian\n",
      "0.0228\n",
      "0.0147\n",
      "Pacific\n",
      "0.0007\n",
      "0.0007\n",
      "Other\n",
      "0.0165\n",
      "0.0098\n",
      "Total time: 40.3 mins\n",
      "Louisiana reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Louisiana Time: 2814.66\n",
      "-------------------\n",
      "White\n",
      "0.5297 dmg\n",
      "0.6201 pop\n",
      "Black\n",
      "0.4029\n",
      "0.3222\n",
      "Native\n",
      "0.0041\n",
      "0.0057\n",
      "Asian\n",
      "0.0213\n",
      "0.0173\n",
      "Pacific\n",
      "0.0002\n",
      "0.0003\n",
      "Other\n",
      "0.0197\n",
      "0.0141\n",
      "Total time: 47.1 mins\n",
      "Maine reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Maine Time: 724.22\n",
      "-------------------\n",
      "White\n",
      "0.9041 dmg\n",
      "0.9431 pop\n",
      "Black\n",
      "0.0375\n",
      "0.0138\n",
      "Native\n",
      "0.0046\n",
      "0.0065\n",
      "Asian\n",
      "0.0223\n",
      "0.0113\n",
      "Pacific\n",
      "0.0002\n",
      "0.0003\n",
      "Other\n",
      "0.0034\n",
      "0.0027\n",
      "Total time: 12.2 mins\n",
      "Maryland reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Maryland Time: 920.24\n",
      "-------------------\n",
      "White\n",
      "0.4931 dmg\n",
      "0.5554 pop\n",
      "Black\n",
      "0.3465\n",
      "0.2989\n",
      "Native\n",
      "0.0032\n",
      "0.0028\n",
      "Asian\n",
      "0.0751\n",
      "0.0628\n",
      "Pacific\n",
      "0.0006\n",
      "0.0005\n",
      "Other\n",
      "0.0458\n",
      "0.0452\n",
      "Total time: 15.5 mins\n",
      "Massachusetts reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Massachusetts Time: 1142.56\n",
      "-------------------\n",
      "White\n",
      "0.7135 dmg\n",
      "0.7807 pop\n",
      "Black\n",
      "0.0957\n",
      "0.0763\n",
      "Native\n",
      "0.0022\n",
      "0.0022\n",
      "Asian\n",
      "0.0923\n",
      "0.066\n",
      "Pacific\n",
      "0.0006\n",
      "0.0004\n",
      "Other\n",
      "0.0542\n",
      "0.0418\n",
      "Total time: 19.3 mins\n",
      "Michigan reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Michigan Time: 2028.0\n",
      "-------------------\n",
      "White\n",
      "0.6472 dmg\n",
      "0.7841 pop\n",
      "Black\n",
      "0.2534\n",
      "0.1379\n",
      "Native\n",
      "0.0041\n",
      "0.0054\n",
      "Asian\n",
      "0.0437\n",
      "0.0313\n",
      "Pacific\n",
      "0.0005\n",
      "0.0003\n",
      "Other\n",
      "0.0164\n",
      "0.0118\n",
      "Total time: 34.3 mins\n",
      "Minnesota reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Minnesota Time: 14540.58\n",
      "-------------------\n",
      "White\n",
      "0.7207 dmg\n",
      "0.8285 pop\n",
      "Black\n",
      "0.1297\n",
      "0.0641\n",
      "Native\n",
      "0.0083\n",
      "0.0104\n",
      "Asian\n",
      "0.0718\n",
      "0.0482\n",
      "Pacific\n",
      "0.0005\n",
      "0.0004\n",
      "Other\n",
      "0.03\n",
      "0.0187\n",
      "Total time: 243.8 mins\n",
      "Mississippi reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Mississippi Time: 4572.98\n",
      "-------------------\n",
      "White\n",
      "0.5259 dmg\n",
      "0.5841 pop\n",
      "Black\n",
      "0.4337\n",
      "0.3772\n",
      "Native\n",
      "0.003\n",
      "0.0048\n",
      "Asian\n",
      "0.0121\n",
      "0.0099\n",
      "Pacific\n",
      "0.0003\n",
      "0.0002\n",
      "Other\n",
      "0.0109\n",
      "0.0103\n",
      "Total time: 76.5 mins\n",
      "Missouri reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Missouri Time: 5467.98\n",
      "-------------------\n",
      "White\n",
      "0.7068 dmg\n",
      "0.8216 pop\n",
      "Black\n",
      "0.2113\n",
      "0.1149\n",
      "Native\n",
      "0.0032\n",
      "0.0044\n",
      "Asian\n",
      "0.0311\n",
      "0.0198\n",
      "Pacific\n",
      "0.0016\n",
      "0.0013\n",
      "Other\n",
      "0.0152\n",
      "0.0117\n",
      "Total time: 91.5 mins\n",
      "Montana reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Montana Time: 30624.5\n",
      "-------------------\n",
      "White\n",
      "0.9034 dmg\n",
      "0.8854 pop\n",
      "Black\n",
      "0.0069\n",
      "0.005\n",
      "Native\n",
      "0.0373\n",
      "0.0636\n",
      "Asian\n",
      "0.0099\n",
      "0.0079\n",
      "Pacific\n",
      "0.0007\n",
      "0.0008\n",
      "Other\n",
      "0.0072\n",
      "0.0067\n",
      "Total time: 511.2 mins\n",
      "Nebraska reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Nebraska Time: 4415.5\n",
      "-------------------\n",
      "White\n",
      "0.8299 dmg\n",
      "0.8706 pop\n",
      "Black\n",
      "0.0751\n",
      "0.0483\n",
      "Native\n",
      "0.0063\n",
      "0.0092\n",
      "Asian\n",
      "0.032\n",
      "0.0238\n",
      "Pacific\n",
      "0.0011\n",
      "0.0007\n",
      "Other\n",
      "0.0225\n",
      "0.021\n",
      "Total time: 73.9 mins\n",
      "Nevada reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Nevada Time: 3635.32\n",
      "-------------------\n",
      "White\n",
      "0.6298 dmg\n",
      "0.6559 pop\n",
      "Black\n",
      "0.0983\n",
      "0.0912\n",
      "Native\n",
      "0.0126\n",
      "0.0128\n",
      "Asian\n",
      "0.0849\n",
      "0.0815\n",
      "Pacific\n",
      "0.0071\n",
      "0.0067\n",
      "Other\n",
      "0.1179\n",
      "0.1026\n",
      "Total time: 60.7 mins\n",
      "NewHampshire reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: NewHampshire Time: 327.3\n",
      "-------------------\n",
      "White\n",
      "0.8882 dmg\n",
      "0.9288 pop\n",
      "Black\n",
      "0.0321\n",
      "0.016\n",
      "Native\n",
      "0.0011\n",
      "0.0015\n",
      "Asian\n",
      "0.0437\n",
      "0.0268\n",
      "Pacific\n",
      "0.0002\n",
      "0.0003\n",
      "Other\n",
      "0.0094\n",
      "0.0056\n",
      "Total time: 5.5 mins\n",
      "NewJersey reading files, housing density, noise , attribute to demos \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State: NewJersey Time: 1245.71\n",
      "-------------------\n",
      "White\n",
      "0.5786 dmg\n",
      "0.6778 pop\n",
      "Black\n",
      "0.1932\n",
      "0.1346\n",
      "Native\n",
      "0.0026\n",
      "0.0022\n",
      "Asian\n",
      "0.1115\n",
      "0.0946\n",
      "Pacific\n",
      "0.0004\n",
      "0.0004\n",
      "Other\n",
      "0.0828\n",
      "0.0629\n",
      "Total time: 20.9 mins\n",
      "NewMexico reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: NewMexico Time: 5371.41\n",
      "-------------------\n",
      "White\n",
      "0.7521 dmg\n",
      "0.7481 pop\n",
      "Black\n",
      "0.0288\n",
      "0.0211\n",
      "Native\n",
      "0.0586\n",
      "0.0955\n",
      "Asian\n",
      "0.0233\n",
      "0.0156\n",
      "Pacific\n",
      "0.0007\n",
      "0.0008\n",
      "Other\n",
      "0.0917\n",
      "0.0863\n",
      "Total time: 89.7 mins\n",
      "NewYork reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: NewYork Time: 1934.04\n",
      "-------------------\n",
      "White\n",
      "0.536 dmg\n",
      "0.6366 pop\n",
      "Black\n",
      "0.1745\n",
      "0.1566\n",
      "Native\n",
      "0.0048\n",
      "0.0041\n",
      "Asian\n",
      "0.1207\n",
      "0.0842\n",
      "Pacific\n",
      "0.0005\n",
      "0.0005\n",
      "Other\n",
      "0.1139\n",
      "0.0866\n",
      "Total time: 32.6 mins\n",
      "NorthCarolina reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: NorthCarolina Time: 3744.09\n",
      "-------------------\n",
      "White\n",
      "0.6082 dmg\n",
      "0.6868 pop\n",
      "Black\n",
      "0.2786\n",
      "0.2144\n",
      "Native\n",
      "0.0074\n",
      "0.0121\n",
      "Asian\n",
      "0.0408\n",
      "0.0285\n",
      "Pacific\n",
      "0.0007\n",
      "0.0007\n",
      "Other\n",
      "0.0357\n",
      "0.0309\n",
      "Total time: 62.7 mins\n",
      "NorthDakota reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: NorthDakota Time: 3550.32\n",
      "-------------------\n",
      "White\n",
      "0.8414 dmg\n",
      "0.8658 pop\n",
      "Black\n",
      "0.0549\n",
      "0.0291\n",
      "Native\n",
      "0.0368\n",
      "0.0529\n",
      "Asian\n",
      "0.0224\n",
      "0.0145\n",
      "Pacific\n",
      "0.0019\n",
      "0.0011\n",
      "Other\n",
      "0.0126\n",
      "0.0107\n",
      "Total time: 59.4 mins\n",
      "Ohio reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Ohio Time: 3673.29\n",
      "-------------------\n",
      "White\n",
      "0.7024 dmg\n",
      "0.813 pop\n",
      "Black\n",
      "0.2139\n",
      "0.1241\n",
      "Native\n",
      "0.0024\n",
      "0.002\n",
      "Asian\n",
      "0.0305\n",
      "0.0222\n",
      "Pacific\n",
      "0.0004\n",
      "0.0003\n",
      "Other\n",
      "0.0137\n",
      "0.0097\n",
      "Total time: 61.8 mins\n",
      "Oklahoma reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Oklahoma Time: 6679.28\n",
      "-------------------\n",
      "White\n",
      "0.6912 dmg\n",
      "0.7232 pop\n",
      "Black\n",
      "0.1051\n",
      "0.0728\n",
      "Native\n",
      "0.0532\n",
      "0.0762\n",
      "Asian\n",
      "0.0311\n",
      "0.0217\n",
      "Pacific\n",
      "0.0019\n",
      "0.0016\n",
      "Other\n",
      "0.0364\n",
      "0.0271\n",
      "Total time: 111.7 mins\n",
      "Oregon reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Oregon Time: 8941.33\n",
      "-------------------\n",
      "White\n",
      "0.8123 dmg\n",
      "0.8429 pop\n",
      "Black\n",
      "0.0316\n",
      "0.0191\n",
      "Native\n",
      "0.0098\n",
      "0.0116\n",
      "Asian\n",
      "0.0539\n",
      "0.0437\n",
      "Pacific\n",
      "0.0062\n",
      "0.004\n",
      "Other\n",
      "0.0331\n",
      "0.0307\n",
      "Total time: 149.3 mins\n",
      "Pennsylvania reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Pennsylvania Time: 3097.5\n",
      "-------------------\n",
      "White\n",
      "0.7181 dmg\n",
      "0.8053 pop\n",
      "Black\n",
      "0.1608\n",
      "0.1118\n",
      "Native\n",
      "0.0025\n",
      "0.0019\n",
      "Asian\n",
      "0.0545\n",
      "0.0341\n",
      "Pacific\n",
      "0.0004\n",
      "0.0003\n",
      "Other\n",
      "0.028\n",
      "0.0215\n",
      "Total time: 52.1 mins\n",
      "RhodeIsland reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: RhodeIsland Time: 211.51\n",
      "-------------------\n",
      "White\n",
      "0.7145 dmg\n",
      "0.8046 pop\n",
      "Black\n",
      "0.1071\n",
      "0.0677\n",
      "Native\n",
      "0.0065\n",
      "0.005\n",
      "Asian\n",
      "0.047\n",
      "0.034\n",
      "Pacific\n",
      "0.0009\n",
      "0.0008\n",
      "Other\n",
      "0.0866\n",
      "0.0547\n",
      "Total time: 3.6 mins\n",
      "SouthCarolina reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: SouthCarolina Time: 11040.37\n",
      "-------------------\n",
      "White\n",
      "0.6199 dmg\n",
      "0.6716 pop\n",
      "Black\n",
      "0.3078\n",
      "0.2677\n",
      "Native\n",
      "0.0032\n",
      "0.0035\n",
      "Asian\n",
      "0.0222\n",
      "0.0157\n",
      "Pacific\n",
      "0.0013\n",
      "0.0008\n",
      "Other\n",
      "0.0227\n",
      "0.0176\n",
      "Total time: 184.8 mins\n",
      "SouthDakota reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: SouthDakota Time: 7746.45\n",
      "-------------------\n",
      "White\n",
      "0.8522 dmg\n",
      "0.8427 pop\n",
      "Black\n",
      "0.0414\n",
      "0.0201\n",
      "Native\n",
      "0.0384\n",
      "0.0875\n",
      "Asian\n",
      "0.0252\n",
      "0.0145\n",
      "Pacific\n",
      "0.001\n",
      "0.0006\n",
      "Other\n",
      "0.0132\n",
      "0.0083\n",
      "Total time: 129.4 mins\n",
      "Tennessee reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Tennessee Time: 8118.17\n",
      "-------------------\n",
      "White\n",
      "0.6425 dmg\n",
      "0.7758 pop\n",
      "Black\n",
      "0.2826\n",
      "0.1676\n",
      "Native\n",
      "0.0026\n",
      "0.0027\n",
      "Asian\n",
      "0.0267\n",
      "0.0175\n",
      "Pacific\n",
      "0.0007\n",
      "0.0006\n",
      "Other\n",
      "0.0193\n",
      "0.0138\n",
      "Total time: 135.7 mins\n",
      "Texas reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Texas Time: 21449.47\n",
      "-------------------\n",
      "White\n",
      "0.6825 dmg\n",
      "0.7397 pop\n",
      "Black\n",
      "0.1585\n",
      "0.1213\n",
      "Native\n",
      "0.0051\n",
      "0.005\n",
      "Asian\n",
      "0.056\n",
      "0.048\n",
      "Pacific\n",
      "0.001\n",
      "0.0009\n",
      "Other\n",
      "0.0672\n",
      "0.0582\n",
      "Total time: 358.6 mins\n",
      "Utah reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Utah Time: 9129.28\n",
      "-------------------\n",
      "White\n",
      "0.8279 dmg\n",
      "0.8643 pop\n",
      "Black\n",
      "0.0178\n",
      "0.0119\n",
      "Native\n",
      "0.0107\n",
      "0.0109\n",
      "Asian\n",
      "0.0309\n",
      "0.0232\n",
      "Pacific\n",
      "0.012\n",
      "0.0089\n",
      "Other\n",
      "0.0649\n",
      "0.0504\n",
      "Total time: 152.3 mins\n",
      "Vermont reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Vermont Time: 267.37\n",
      "-------------------\n",
      "White\n",
      "0.9191 dmg\n",
      "0.9416 pop\n",
      "Black\n",
      "0.0201\n",
      "0.0136\n",
      "Native\n",
      "0.0031\n",
      "0.0034\n",
      "Asian\n",
      "0.0298\n",
      "0.0168\n",
      "Pacific\n",
      "0.0005\n",
      "0.0005\n",
      "Other\n",
      "0.0057\n",
      "0.0039\n",
      "Total time: 4.5 mins\n",
      "Virginia reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Virginia Time: 7766.83\n",
      "-------------------\n",
      "White\n",
      "0.6002 dmg\n",
      "0.6763 pop\n",
      "Black\n",
      "0.2275\n",
      "0.1918\n",
      "Native\n",
      "0.0028\n",
      "0.0028\n",
      "Asian\n",
      "0.0901\n",
      "0.064\n",
      "Pacific\n",
      "0.0007\n",
      "0.0007\n",
      "Other\n",
      "0.033\n",
      "0.0265\n",
      "Total time: 129.7 mins\n",
      "Washington reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Washington Time: 10691.93\n",
      "-------------------\n",
      "White\n",
      "0.6731 dmg\n",
      "0.7538 pop\n",
      "Black\n",
      "0.0595\n",
      "0.038\n",
      "Native\n",
      "0.0099\n",
      "0.0128\n",
      "Asian\n",
      "0.1374\n",
      "0.0853\n",
      "Pacific\n",
      "0.0082\n",
      "0.0066\n",
      "Other\n",
      "0.0462\n",
      "0.045\n",
      "Total time: 178.5 mins\n",
      "WestVirginia reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: WestVirginia Time: 16973.83\n",
      "-------------------\n",
      "White\n",
      "0.8831 dmg\n",
      "0.9308 pop\n",
      "Black\n",
      "0.0682\n",
      "0.0369\n",
      "Native\n",
      "0.0023\n",
      "0.002\n",
      "Asian\n",
      "0.0122\n",
      "0.008\n",
      "Pacific\n",
      "0.0001\n",
      "0.0002\n",
      "Other\n",
      "0.007\n",
      "0.0044\n",
      "Total time: 283.3 mins\n",
      "Wisconsin reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Wisconsin Time: 6776.65\n",
      "-------------------\n",
      "White\n",
      "0.7464 dmg\n",
      "0.8543 pop\n",
      "Black\n",
      "0.1346\n",
      "0.0641\n",
      "Native\n",
      "0.0064\n",
      "0.0089\n",
      "Asian\n",
      "0.0456\n",
      "0.0279\n",
      "Pacific\n",
      "0.0005\n",
      "0.0004\n",
      "Other\n",
      "0.0345\n",
      "0.0204\n",
      "Total time: 113.4 mins\n",
      "Wyoming reading files, housing density, noise , attribute to demos \n",
      "\n",
      "State: Wyoming Time: 6413.17\n",
      "-------------------\n",
      "White\n",
      "0.9085 dmg\n",
      "0.9144 pop\n",
      "Black\n",
      "0.0138\n",
      "0.0096\n",
      "Native\n",
      "0.016\n",
      "0.0244\n",
      "Asian\n",
      "0.0107\n",
      "0.0086\n",
      "Pacific\n",
      "0.0008\n",
      "0.001\n",
      "Other\n",
      "0.0172\n",
      "0.0152\n",
      "Total time: 107.0 mins\n"
     ]
    }
   ],
   "source": [
    "# Main running Section #\n",
    "#calls the primary function 'equity' for each state\n",
    "#alternatively it can be called for states individually\n",
    "fails = []\n",
    "for c in range(len(house_value['State'])):\n",
    "    try:\n",
    "        equity(c)\n",
    "    except Exception as e:\n",
    "        print(\"\\n\",house_value['State'][c], \"failed\")\n",
    "        print(e)\n",
    "        fails.append(house_value['State'][c])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pandas.DataFrame(result)\n",
    "\n",
    "########***##################\n",
    "#add US row\n",
    "#first sum each column, store in list\n",
    "#add list as row to results\n",
    "###############***###########\n",
    "\n",
    "us = [i for i in results.loc[:,results.columns!='state'].apply(lambda col: sum(col), axis=0)]\n",
    "us.insert(0,'US')\n",
    "results.loc[len(results.index)] = us\n",
    "results['urban_pct'] = results['urban_dmg'] / (results['urban_dmg'] + results['rural_dmg'])\n",
    "results['rural_pct'] = results['rural_dmg'] / (results['urban_dmg'] + results['rural_dmg'])\n",
    "\n",
    "for i in demos:\n",
    "    results[i+'_ndp'] = results[i+'_dmg']/results['state_dmg'] / (results[i+'_pop']/results['state_pop'])\n",
    "\n",
    "keep = ['state','urban_pct','rural_pct']#,'white_ndp','black_ndp','native_ndp','asian_ndp','pacific_ndp','other_ndp']\n",
    "for i in demos:\n",
    "    keep.append(i+'_ndp')\n",
    "results_ = results[keep]\n",
    "results2 = pandas.melt(results_,id_vars=['state'],var_name='metrics',value_name='values')\n",
    "results2[\"Demographic\"] = results2.apply(lambda row: row['metrics'][:-4], axis=1)\n",
    "results2['metrics'] = results2.apply(lambda row: row['metrics'][-3:], axis=1)\n",
    "\n",
    "#may want to include date\n",
    "results2.to_csv(root+\"\\\\Equity_long.csv\")\n",
    "county.to_csv(root+\"\\\\Equity_county.csv\")\n",
    "census.to_csv(root+\"\\\\Equity_census.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
